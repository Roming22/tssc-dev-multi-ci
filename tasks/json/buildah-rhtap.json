{
  "apiVersion": "tekton.dev/v1",
  "kind": "Task",
  "metadata": {
    "labels": {
      "app.kubernetes.io/version": "0.1",
      "build.appstudio.redhat.com/build_type": "docker"
    },
    "annotations": {
      "tekton.dev/pipelines.minVersion": "0.12.1",
      "tekton.dev/tags": "containers, rhtap"
    },
    "name": "buildah-rhtap"
  },
  "spec": {
    "description": "Buildah task builds source code into a container image and pushes the image into container registry using buildah tool.\nIn addition it generates a SBOM file, injects the SBOM file into final container image and pushes the SBOM file as separate image using cosign tool.",
    "params": [
      {
        "description": "Reference of the image buildah will produce.",
        "name": "IMAGE",
        "type": "string"
      },
      {
        "default": "./Dockerfile",
        "description": "Path to the Dockerfile to build.",
        "name": "DOCKERFILE",
        "type": "string"
      },
      {
        "default": ".",
        "description": "Path to the directory to use as context.",
        "name": "CONTEXT",
        "type": "string"
      },
      {
        "default": "true",
        "description": "Verify the TLS on the registry endpoint (for push/pull to a non-TLS registry)",
        "name": "TLSVERIFY",
        "type": "string"
      },
      {
        "name": "BUILD_ARGS",
        "description": "Array of --build-arg values (\"arg=value\" strings)",
        "type": "array",
        "default": []
      },
      {
        "name": "BUILD_ARGS_FILE",
        "description": "Path to a file with build arguments, see https://www.mankier.com/1/buildah-build#--build-arg-file",
        "type": "string",
        "default": ""
      }
    ],
    "results": [
      {
        "description": "Digest of the image just built",
        "name": "IMAGE_DIGEST"
      },
      {
        "description": "Image repository where the built image was pushed",
        "name": "IMAGE_URL"
      },
      {
        "description": "Digests of the base images used for build",
        "name": "BASE_IMAGES_DIGESTS"
      },
      {
        "description": "Link to the SBOM layer pushed to the registry as part of an OCI artifact.",
        "name": "SBOM_BLOB_URL"
      }
    ],
    "stepTemplate": {
      "env": [
        {
          "name": "STORAGE_DRIVER",
          "value": "vfs"
        },
        {
          "name": "CONTEXT",
          "value": "$(params.CONTEXT)"
        },
        {
          "name": "DOCKERFILE",
          "value": "$(params.DOCKERFILE)"
        },
        {
          "name": "IMAGE",
          "value": "$(params.IMAGE)"
        },
        {
          "name": "TLSVERIFY",
          "value": "$(params.TLSVERIFY)"
        },
        {
          "name": "BUILD_ARGS_FILE",
          "value": "$(params.BUILD_ARGS_FILE)"
        }
      ]
    },
    "steps": [
      {
        "name": "build",
        "image": "registry.access.redhat.com/ubi9/buildah@sha256:3b11aae36f6c762e01731952ee6fb8e89c41660ce410e4c30d0bfc6496bca93c",
        "args": [
          "$(params.BUILD_ARGS[*])"
        ],
        "script": "# Check if the Dockerfile exists\nSOURCE_CODE_DIR=source\nif [ -e \"$SOURCE_CODE_DIR/$CONTEXT/$DOCKERFILE\" ]; then\n  dockerfile_path=\"$SOURCE_CODE_DIR/$CONTEXT/$DOCKERFILE\"\nelif [ -e \"$SOURCE_CODE_DIR/$DOCKERFILE\" ]; then\n  dockerfile_path=\"$SOURCE_CODE_DIR/$DOCKERFILE\"\nelse\n  echo \"Cannot find Dockerfile $DOCKERFILE\"\n  exit 1\nfi\n\nBUILDAH_ARGS=()\nif [ -n \"${BUILD_ARGS_FILE}\" ]; then\n  BUILDAH_ARGS+=(\"--build-arg-file=${SOURCE_CODE_DIR}/${BUILD_ARGS_FILE}\")\nfi\n\nfor build_arg in \"$@\"; do\n  BUILDAH_ARGS+=(\"--build-arg=$build_arg\")\ndone\n\n# Build the image\nbuildah build \\\n  \"${BUILDAH_ARGS[@]}\" \\\n  --tls-verify=$TLSVERIFY \\\n  --ulimit nofile=4096:4096 \\\n  -f \"$dockerfile_path\" -t $IMAGE $SOURCE_CODE_DIR/$CONTEXT\n\n# Push the image\nbuildah push \\\n  --tls-verify=$TLSVERIFY \\\n  --retry=5 \\\n  --digestfile /tmp/files/image-digest $IMAGE \\\n  docker://$IMAGE\n\n# Set task results\nbuildah images --format '{{ .Name }}:{{ .Tag }}@{{ .Digest }}' | grep -v $IMAGE > $(results.BASE_IMAGES_DIGESTS.path)\ncat /tmp/files/image-digest | tee $(results.IMAGE_DIGEST.path)\necho -n \"$IMAGE\" | tee $(results.IMAGE_URL.path)\n\n# Save the image so it can be used in the generate-sbom step\nbuildah push \"$IMAGE\" oci:/tmp/files/image\n",
        "securityContext": {
          "capabilities": {
            "add": [
              "SETFCAP"
            ]
          }
        },
        "volumeMounts": [
          {
            "mountPath": "/var/lib/containers",
            "name": "varlibcontainers"
          },
          {
            "mountPath": "/tmp/files",
            "name": "tmpfiles"
          }
        ],
        "workingDir": "$(workspaces.source.path)"
      },
      {
        "name": "generate-sboms",
        "image": "registry.redhat.io/rh-syft-tech-preview/syft-rhel9:1.0.1@sha256:27c268d678103a27b6964c2cd5169040941b7304d0078f9727789ffb8ffba370",
        "workingDir": "$(workspaces.source.path)/source",
        "script": "syft dir:$(workspaces.source.path)/source --output cyclonedx-json@1.5=/tmp/files/sbom-source.json\nsyft oci-dir:/tmp/files/image --output cyclonedx-json@1.5=/tmp/files/sbom-image.json\n",
        "volumeMounts": [
          {
            "mountPath": "/var/lib/containers",
            "name": "varlibcontainers"
          },
          {
            "mountPath": "/tmp/files",
            "name": "tmpfiles"
          }
        ]
      },
      {
        "name": "merge-sboms",
        "image": "registry.access.redhat.com/ubi8/python-311@sha256:634918e88adb803029a99cb1a5a6bb42834c2560ee098e87677efdaf7309380d",
        "env": [
          {
            "name": "RESULT_PATH",
            "value": "$(results.SBOM_BLOB_URL.path)"
          }
        ],
        "script": "#!/bin/python3\nimport hashlib\nimport json\nimport os\nimport re\n\n### load SBOMs ###\n\nwith open(\"./sbom-image.json\") as f:\n  image_sbom = json.load(f)\n\nwith open(\"./sbom-source.json\") as f:\n  source_sbom = json.load(f)\n\n\n### attempt to deduplicate components ###\n\ncomponent_list = image_sbom.get(\"components\", [])\nexisting_purls = [c[\"purl\"] for c in component_list if \"purl\" in c]\n\nfor component in source_sbom.get(\"components\", []):\n  if \"purl\" in component:\n    if component[\"purl\"] not in existing_purls:\n      component_list.append(component)\n      existing_purls.append(component[\"purl\"])\n  else:\n    # We won't try to deduplicate components that lack a purl.\n    # This should only happen with operating-system type components,\n    # which are only reported in the image SBOM.\n    component_list.append(component)\n\ncomponent_list.sort(key=lambda c: c[\"type\"] + c[\"name\"])\nimage_sbom[\"components\"] = component_list\n\n\n### write the CycloneDX unified SBOM ###\n\nwith open(\"./sbom-cyclonedx.json\", \"w\") as f:\n  json.dump(image_sbom, f, indent=4)\n\n\n### write the SBOM blob URL result ###\n\nwith open(\"./sbom-cyclonedx.json\", \"rb\") as f:\n  sbom_digest = hashlib.file_digest(f, \"sha256\").hexdigest()\n\n# https://github.com/opencontainers/distribution-spec/blob/main/spec.md?plain=1#L160\ntag_regex = \"[a-zA-Z0-9_][a-zA-Z0-9._-]{0,127}\"\n\n# the tag must be after a colon, but always at the end of the string\n# this avoids conflict with port numbers\nimage_without_tag = re.sub(f\":{tag_regex}$\", \"\", os.getenv(\"IMAGE\"))\n\nsbom_blob_url = f\"{image_without_tag}@sha256:{sbom_digest}\"\n\nwith open(os.getenv(\"RESULT_PATH\"), \"w\") as f:\n  f.write(sbom_blob_url)\n",
        "volumeMounts": [
          {
            "mountPath": "/tmp/files",
            "name": "tmpfiles"
          }
        ],
        "workingDir": "/tmp/files"
      },
      {
        "name": "upload-sbom",
        "image": "registry.redhat.io/rhtas-tech-preview/cosign-rhel9:0.0.2@sha256:151f4a1e721b644bafe47bf5bfb8844ff27b95ca098cc37f3f6cbedcda79a897",
        "command": [
          "cosign"
        ],
        "args": [
          "attach",
          "sbom",
          "--sbom",
          "sbom-cyclonedx.json",
          "--type",
          "cyclonedx",
          "$(params.IMAGE)"
        ],
        "volumeMounts": [
          {
            "mountPath": "/tmp/files",
            "name": "tmpfiles"
          }
        ],
        "workingDir": "/tmp/files"
      }
    ],
    "volumes": [
      {
        "emptyDir": {},
        "name": "varlibcontainers"
      },
      {
        "emptyDir": {},
        "name": "tmpfiles"
      }
    ],
    "workspaces": [
      {
        "name": "source",
        "description": "Workspace containing the source code to build."
      }
    ]
  }
}
